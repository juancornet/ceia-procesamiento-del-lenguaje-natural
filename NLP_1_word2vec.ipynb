{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 1 - word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue5hxxkdAQJg"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Word2vect\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCED1hh-Ioyf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUbfVnzIIoMj"
      },
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOa4JPSCJ29"
      },
      "source": [
        "### Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIO7b8GjAC17"
      },
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHxBRNzCMOS"
      },
      "source": [
        "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
        "- Cada documento transformarlo en una lista de términos\n",
        "- Armar un vector de términos no repetidos de todos los documentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZqTOZzDI7uv"
      },
      "source": [
        "new_corpus = []\n",
        "for document in corpus:\n",
        "  document = document.split(\" \")\n",
        "  new_corpus.append(document)\n",
        "\n",
        "vocabulary = {}\n",
        "index = 0\n",
        "for document in new_corpus:\n",
        "  for term in document:\n",
        "    if not term in vocabulary:\n",
        "      vocabulary[term] = index\n",
        "      index +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF8t2NXqCA8R",
        "outputId": "9d7a7a27-05ad-4182-85e3-a64a71e6cfd7"
      },
      "source": [
        "vocabulary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'de': 6,\n",
              " 'dia': 1,\n",
              " 'el': 5,\n",
              " 'es': 2,\n",
              " 'gracias': 8,\n",
              " 'hoy': 3,\n",
              " 'martes': 4,\n",
              " 'muchas': 7,\n",
              " 'que': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhH983FI7It"
      },
      "source": [
        "### 2- OneHot encoding\n",
        "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os0AAQo6I6Z1"
      },
      "source": [
        "term2onehot = np.eye(len(vocabulary))\n",
        "\n",
        "onehot_corpus = []\n",
        "for document in new_corpus:\n",
        "  onehot_doc = np.zeros((len(document), len(vocabulary)))\n",
        "  for term in range(len(document)):\n",
        "    onehot_doc[term, :] = term2onehot[vocabulary[document[term]]]\n",
        "  onehot_corpus.append(np.array(onehot_doc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNwg1EFZCJrx",
        "outputId": "d0b13202-2f97-4642-afd4-af9ffd5656b5"
      },
      "source": [
        "onehot_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIyWGmCpJVQL"
      },
      "source": [
        "### 3- Vectores de frecuencia\n",
        "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqij_7eHJbUi"
      },
      "source": [
        "freq_corpus = []\n",
        "for document in onehot_corpus:\n",
        "  freq_corpus.append(document.sum(axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vglZ69BQLPFF",
        "outputId": "b02e14bf-d843-45f6-800f-9f71ace7894b"
      },
      "source": [
        "np.array(freq_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 1., 1., 2., 1., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ot8HvWJcBu"
      },
      "source": [
        "### 4- TF-IDF\n",
        "Data una lista de textos, devolver una matriz con la representacion TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waG_oWtpJjRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942617f2-8055-4637-8778-dd5ac5a6668f"
      },
      "source": [
        "df_vocabulary = np.zeros(len(vocabulary))\n",
        "for term in vocabulary:\n",
        "  for document in new_corpus:\n",
        "    if term in document:\n",
        "      df_vocabulary[vocabulary[term]] += 1\n",
        "    \n",
        "df_vocabulary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 2., 2., 2., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGpcspi5LqlP",
        "outputId": "7577fd18-be75-4821-cf9f-0b825c400b58"
      },
      "source": [
        "n_doc = len(corpus)\n",
        "n_doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wcg4I6sMCGc",
        "outputId": "35b1821d-470b-41b1-c422-8168caf12b4b"
      },
      "source": [
        "idf = np.log10(n_doc/df_vocabulary)\n",
        "idf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47712125, 0.17609126, 0.17609126, 0.17609126, 0.17609126,\n",
              "       0.47712125, 0.47712125, 0.47712125, 0.47712125])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHarTFnNMOiU",
        "outputId": "857e31e9-d8b9-4c60-f254-7762a0bf58f1"
      },
      "source": [
        "tf_idf = np.zeros((n_doc, len(vocabulary)))\n",
        "\n",
        "for i in range(n_doc):\n",
        "  tf_idf[i, :] = np.multiply(idf, freq_corpus[i])\n",
        "\n",
        "tf_idf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47712125, 0.17609126, 0.17609126, 0.17609126, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.17609126, 0.17609126, 0.17609126, 0.35218252,\n",
              "        0.47712125, 0.47712125, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.17609126,\n",
              "        0.        , 0.        , 0.47712125, 0.47712125]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMcsfndWJjm_"
      },
      "source": [
        "### 5 - Comparación de documentos\n",
        "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZdiop6IJpZN"
      },
      "source": [
        "def compare_documents(corpus, idx):\n",
        "\n",
        "  # Separo los documentos en terminos\n",
        "  new_corpus = []\n",
        "  for document in corpus:\n",
        "    document = document.split(\" \")\n",
        "    new_corpus.append(document)\n",
        "\n",
        "  # Conformo el vocabulario\n",
        "  vocabulary = {}\n",
        "  index = 0\n",
        "  for document in new_corpus:\n",
        "    for term in document:\n",
        "      if not term in vocabulary:\n",
        "        vocabulary[term] = index\n",
        "        index +=1\n",
        "\n",
        "  # Represento el corpus en One Hot Encoding\n",
        "  term2onehot = np.eye(len(vocabulary))\n",
        "\n",
        "  onehot_corpus = []\n",
        "  for document in new_corpus:\n",
        "    onehot_doc = np.zeros((len(document), len(vocabulary)))\n",
        "    for term in range(len(document)):\n",
        "      onehot_doc[term, :] = term2onehot[vocabulary[document[term]]]\n",
        "    onehot_corpus.append(np.array(onehot_doc))\n",
        "\n",
        "  # Obtengo la frecuencia de cada termino en cada documento del corpus\n",
        "  freq_corpus = []\n",
        "  for document in onehot_corpus:\n",
        "    freq_corpus.append(document.sum(axis=0))\n",
        "  \n",
        "  freq_corpus = np.array(freq_corpus)\n",
        "\n",
        "  # Obtengo la frecuencia de aparicion de los terminos en el corpus\n",
        "  df_vocabulary = np.zeros(len(vocabulary))\n",
        "  for term in vocabulary:\n",
        "    for document in new_corpus:\n",
        "      if term in document:\n",
        "        df_vocabulary[vocabulary[term]] += 1\n",
        "  \n",
        "  n_doc = len(corpus)\n",
        "\n",
        "  # Obtengo la frecuencia inversa de aparicion de los terminos en el corpus\n",
        "  idf = np.log10(n_doc/df_vocabulary)\n",
        "\n",
        "  tf_idf = np.zeros((n_doc, len(vocabulary)))\n",
        "\n",
        "  # Obtengo el indice TF-IDF\n",
        "  for i in range(n_doc):\n",
        "    tf_idf[i, :] = np.multiply(idf, freq_corpus[i])\n",
        "\n",
        "  similarity = np.zeros(n_doc)\n",
        "  for i in range(n_doc):\n",
        "    similarity[i] = cosine_similarity(tf_idf[i,:], tf_idf[idx, :])\n",
        "\n",
        "  return corpus[np.argsort(-similarity)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CD5K9sMPhAO",
        "outputId": "91d41f6a-d96c-4ecd-da96-eb45ba9aa7d3"
      },
      "source": [
        "compare_documents(corpus, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['que dia es hoy', 'martes el dia de hoy es martes',\n",
              "       'martes muchas gracias'], dtype='<U30')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHwlwWEvPj_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}